{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DoHyung08/RL/blob/main/0407value/value_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpjNGju46Ue"
      },
      "source": [
        "# 가치 함수 구하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzG8dprr46Ui"
      },
      "source": [
        "아래는 우리가 다루게 될 환경입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooY85oBA46Uj"
      },
      "outputs": [],
      "source": [
        "# define the 4 * 4 grid environment\n",
        "class GridEnv:\n",
        "    def __init__(self):\n",
        "        self.state_space = [(i, j) for i in range(4) for j in range(4)]\n",
        "        self.action_space = ['up', 'down', 'left', 'right']\n",
        "\n",
        "        self.grid = [\n",
        "            [0, 0, 0, 0],\n",
        "            [0, 0, 0, 0],\n",
        "            [0, 0, 0, 0],\n",
        "            [0, 0, 0, 0]\n",
        "        ]\n",
        "        self.start = (3, 0)\n",
        "        self.goal = (0, 3)\n",
        "        self.rewards = [\n",
        "            [-1, -1, -1, 1],\n",
        "            [-1, -1, -1, -1],\n",
        "            [-1, -1, -1, -1],\n",
        "            [-1, -1, -1, -1]\n",
        "        ]\n",
        "        self.done = [\n",
        "            [0, 0, 0, 1],\n",
        "            [0, 0, 0, 0],\n",
        "            [0, 0, 0, 0],\n",
        "            [0, 0, 0, 0]\n",
        "        ]\n",
        "\n",
        "    def transition(self, state, action):\n",
        "        x, y = state\n",
        "        if action == 'up':\n",
        "            x = max(x - 1, 0)\n",
        "        elif action == 'down':\n",
        "            x = min(x + 1, 3)\n",
        "        elif action == 'left':\n",
        "            y = max(y - 1, 0)\n",
        "        elif action == 'right':\n",
        "            y = min(y + 1, 3)\n",
        "        return (x, y)\n",
        "\n",
        "    def transition_prob(self, next_state, state, action):##\n",
        "        return next_state == self.transition(state, action)##\n",
        "\n",
        "    def reward(self, state, action):\n",
        "        next_state = self.transition(state, action)\n",
        "        x, y = next_state\n",
        "        return self.rewards[x][y]\n",
        "\n",
        "    def reset(self):\n",
        "        self.grid = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
        "        self.state = self.start\n",
        "        return self.start\n",
        "\n",
        "    def step(self, action):\n",
        "        next_state = self.transition(self.state, action)\n",
        "        reward = self.reward(self.state, action)\n",
        "        done = self.done[next_state[0]][next_state[1]]\n",
        "        self.state = next_state\n",
        "        return next_state, reward, done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_PmwT3646Ul",
        "outputId": "ea4d1d28-06a3-4033-ad04-0c523eef2e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial state: (3, 0)\n",
            "Chose action: left\n",
            "New state: (3, 0)\n",
            "Reward: -1\n",
            "Chose action: down\n",
            "New state: (3, 0)\n",
            "Reward: -1\n",
            "Chose action: up\n",
            "New state: (2, 0)\n",
            "Reward: -1\n",
            "Chose action: up\n",
            "New state: (1, 0)\n",
            "Reward: -1\n",
            "Chose action: left\n",
            "New state: (1, 0)\n",
            "Reward: -1\n",
            "Chose action: right\n",
            "New state: (1, 1)\n",
            "Reward: -1\n",
            "Chose action: up\n",
            "New state: (0, 1)\n",
            "Reward: -1\n",
            "Chose action: up\n",
            "New state: (0, 1)\n",
            "Reward: -1\n",
            "Chose action: left\n",
            "New state: (0, 0)\n",
            "Reward: -1\n",
            "Chose action: right\n",
            "New state: (0, 1)\n",
            "Reward: -1\n",
            "Chose action: right\n",
            "New state: (0, 2)\n",
            "Reward: -1\n",
            "Chose action: up\n",
            "New state: (0, 2)\n",
            "Reward: -1\n",
            "Chose action: right\n",
            "New state: (0, 3)\n",
            "Reward: 1\n"
          ]
        }
      ],
      "source": [
        "# Sample code for running the environment\n",
        "import random\n",
        "\n",
        "env = GridEnv()\n",
        "state = env.reset()\n",
        "done = False\n",
        "print(\"Initial state:\", state)\n",
        "while not done:\n",
        "    action = random.choice(env.action_space)\n",
        "    print(\"Chose action:\", action)\n",
        "    state, reward, done = env.step(action)\n",
        "    print(\"New state:\", state)\n",
        "    print(\"Reward:\", reward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfZTylZp46Ul"
      },
      "source": [
        "먼저, 아무 전략이나 만들어봅시다. 단순하게 무조건 위로만 가는 전략을 생각해볼까요~?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8jdo21n46Ul"
      },
      "outputs": [],
      "source": [
        "PI = {s: 'up' for s in env.state_space}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-nijPhP46Um"
      },
      "outputs": [],
      "source": [
        "def visualize_policy(env, PI):\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            if (i, j) == env.goal:\n",
        "                print(\" G \", end='\\t')\n",
        "            else:\n",
        "                print(PI[(i, j)], end='\\t')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VX2P6TJ46Um",
        "outputId": "c5783ad3-ea7f-44bd-da5f-210c2f277e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "up\tup\tup\t G \t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n"
          ]
        }
      ],
      "source": [
        "visualize_policy(env, PI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRFCCtjt46Un"
      },
      "source": [
        "### 가치 평가 단계\n",
        "우리가 가지고 있는 전략이 얼마나 좋은지 평가하려면, 가치 함수를 구하면 됩니다.\n",
        "\n",
        "수업 시간 때 다룬 것처럼, 가치 함수는 이 전략을 따라하면 기대할 수 있는 보상의 총합을 구해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n71phYhA46Un"
      },
      "outputs": [],
      "source": [
        "# Policy Evaluation\n",
        "def policy_evaluation(env, PI, gamma=1):\n",
        "    V = {s: 0 for s in env.state_space}\n",
        "    for _ in range(1000):\n",
        "        delta = 0\n",
        "        for s in env.state_space:\n",
        "\n",
        "            action = PI[s]\n",
        "            next_state = env.transition(s,action)\n",
        "            reward = env.reward(s, action)\n",
        "            V[s] = reward + gamma*V[next_state]\n",
        "\n",
        "    return V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RodXve6K46Uo",
        "outputId": "3c939e6d-969a-407f-8eab-43f9afebf077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1000.00\t-1000.00\t-1000.00\t1000.00\t\n",
            "-1001.00\t-1001.00\t-1001.00\t1001.00\t\n",
            "-1002.00\t-1002.00\t-1002.00\t1000.00\t\n",
            "-1003.00\t-1003.00\t-1003.00\t999.00\t\n"
          ]
        }
      ],
      "source": [
        "V = policy_evaluation(env, PI)\n",
        "# Visualize the value function\n",
        "def visualize_value_function(V):\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            print(f\"{V[(i, j)]:.2f}\", end='\\t')\n",
        "        print()\n",
        "\n",
        "visualize_value_function(V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuFlsO2b46Uo"
      },
      "source": [
        "### 정책 개선 단계\n",
        "\n",
        "주어진 상태의 가치는 이 상태가 얼마나 좋은지를 알려줍니다.\n",
        "\n",
        "따라서, 가치가 큰 방향으로 이동하는 새로운 전략을 세우면, 더 좋은 전략이 될 수 있겠네요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN2QW5MH46Uo"
      },
      "outputs": [],
      "source": [
        "# Policy Improvement\n",
        "def policy_improvement(env, V, PI, gamma=1):#할인 인자 = 1\n",
        "    newPI = {}\n",
        "    for s in env.state_space:\n",
        "        max_v = float('-inf')\n",
        "        for a in env.action_space:\n",
        "            next_state = env.transition(s,a)#가치를 이용해 정책 설정\n",
        "            if(max_v < V[next_state]):\n",
        "              max_v = V[next_state]\n",
        "              newPI[s] = a\n",
        "\n",
        "            # nextReward = env.reward(s,a) ##보상을 이용해 정책 설정\n",
        "            # if nextReward > max_v:\n",
        "            #   max_v = nextReward\n",
        "            #   newPI[s] = a\n",
        "\n",
        "    return newPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBrLx8qu46Uo",
        "outputId": "ef74f614-2bb6-4155-926a-d77c18517b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "up\tup\tright\t G \t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n"
          ]
        }
      ],
      "source": [
        "PI = policy_improvement(env, V, PI)\n",
        "visualize_policy(env, PI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCbezsXe46Uo"
      },
      "source": [
        "### 정책 반복법 시행하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQvxquPL46Uq",
        "outputId": "c1d18219-b7a8-41d7-d22e-4ae70f9768fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "up\tup\tright\t G \t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n",
            "-1000.00\t-1000.00\t-1000.00\t1000.00\t\n",
            "-1001.00\t-1001.00\t-1001.00\t1001.00\t\n",
            "-1002.00\t-1002.00\t-1002.00\t1000.00\t\n",
            "-1003.00\t-1003.00\t-1003.00\t999.00\t\n",
            "\n",
            "up\tup\tright\t G \t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n",
            "-1000.00\t-1000.00\t1000.00\t1000.00\t\n",
            "-1001.00\t-1001.00\t999.00\t1001.00\t\n",
            "-1002.00\t-1002.00\t998.00\t1000.00\t\n",
            "-1003.00\t-1003.00\t997.00\t999.00\t\n",
            "\n",
            "up\tup\tright\t G \t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n",
            "up\tup\tup\tup\t\n",
            "-1000.00\t-1000.00\t1000.00\t1000.00\t\n",
            "-1001.00\t-1001.00\t999.00\t1001.00\t\n",
            "-1002.00\t-1002.00\t998.00\t1000.00\t\n",
            "-1003.00\t-1003.00\t997.00\t999.00\t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "PI = {s: 'up' for s in env.state_space}\n",
        "for _ in range(3):\n",
        "    V = policy_evaluation(env, PI)\n",
        "    PI = policy_improvement(env, V, PI)\n",
        "    visualize_policy(env, PI)\n",
        "    visualize_value_function(V)\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rllib",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}